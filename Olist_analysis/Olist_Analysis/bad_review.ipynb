{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-16T01:55:22.500335Z",
     "start_time": "2024-07-16T01:54:57.706594Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# 读取CSV文件并指定数据类型\n",
    "data = pd.read_csv(\"C:/Users/KK Chan/Downloads/review_analysis(ML).csv\", dtype={'review_comment_title': str, 'review_comment_message': str}, low_memory=False)\n",
    "\n",
    "# 筛选出'predicted_sentiment'等于3的行\n",
    "filtered_data = data[data['predicted_sentiment'] == 0]\n",
    "\n",
    "# 获取'review_text'列的值\n",
    "review_texts = filtered_data['review_text'].tolist()\n",
    "\n",
    "# 創建一個空的詞語列表\n",
    "words = []\n",
    "\n",
    "# 遍歷每個評論消息\n",
    "for message in review_texts:\n",
    "    # 利用NLTK庫的詞語分詞功能將評論消息分詞並轉換為小寫\n",
    "    tokens = word_tokenize(str(message).lower())\n",
    "    # 過濾停用詞\n",
    "    tokens = [word for word in tokens if word.isalnum() and word not in stopwords.words('english')]\n",
    "    # 將分詞結果添加到詞語列表中\n",
    "    words.extend(tokens)\n",
    "\n",
    "# 使用Counter進行詞語統計，獲取最常見的50個詞語\n",
    "most_common_words = Counter(words).most_common(50)\n",
    "\n",
    "\n",
    "# 輸出結果\n",
    "for word, count in most_common_words:\n",
    "    print(f'{word}: {count}')\n",
    "print(most_common_words)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\KK\n",
      "[nltk_data]     Chan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\KK\n",
      "[nltk_data]     Chan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product: 8097\n",
      "received: 3575\n",
      "delivered: 2199\n",
      "bought: 2096\n",
      "one: 1998\n",
      "didnt: 1926\n",
      "delivery: 1776\n",
      "arrived: 1764\n",
      "receive: 1594\n",
      "came: 1123\n",
      "im: 1099\n",
      "order: 1087\n",
      "yet: 1047\n",
      "havent: 1021\n",
      "time: 1010\n",
      "waiting: 1002\n",
      "still: 953\n",
      "purchase: 935\n",
      "store: 901\n",
      "two: 895\n",
      "2: 809\n",
      "like: 803\n",
      "already: 802\n",
      "sent: 780\n",
      "dont: 732\n",
      "recommend: 699\n",
      "would: 698\n",
      "purchased: 686\n",
      "want: 682\n",
      "products: 680\n",
      "1: 673\n",
      "arrive: 636\n",
      "wrong: 634\n",
      "post: 628\n",
      "far: 612\n",
      "made: 611\n",
      "paid: 607\n",
      "return: 589\n",
      "office: 575\n",
      "missing: 564\n",
      "quality: 559\n",
      "website: 559\n",
      "deadline: 553\n",
      "even: 542\n",
      "another: 538\n",
      "response: 529\n",
      "lannister: 527\n",
      "different: 527\n",
      "know: 499\n",
      "days: 492\n",
      "[('product', 8097), ('received', 3575), ('delivered', 2199), ('bought', 2096), ('one', 1998), ('didnt', 1926), ('delivery', 1776), ('arrived', 1764), ('receive', 1594), ('came', 1123), ('im', 1099), ('order', 1087), ('yet', 1047), ('havent', 1021), ('time', 1010), ('waiting', 1002), ('still', 953), ('purchase', 935), ('store', 901), ('two', 895), ('2', 809), ('like', 803), ('already', 802), ('sent', 780), ('dont', 732), ('recommend', 699), ('would', 698), ('purchased', 686), ('want', 682), ('products', 680), ('1', 673), ('arrive', 636), ('wrong', 634), ('post', 628), ('far', 612), ('made', 611), ('paid', 607), ('return', 589), ('office', 575), ('missing', 564), ('quality', 559), ('website', 559), ('deadline', 553), ('even', 542), ('another', 538), ('response', 529), ('lannister', 527), ('different', 527), ('know', 499), ('days', 492)]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T01:56:09.094756Z",
     "start_time": "2024-07-16T01:56:09.077737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import csv\n",
    "\n",
    "filename = 'bad_review.csv'\n",
    "\n",
    "with open(filename, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(most_common_words)"
   ],
   "id": "f3bf14c91fa1c79b",
   "outputs": [],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
